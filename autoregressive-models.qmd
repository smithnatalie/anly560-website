---
title: "ARMA/ARIMA/SARIMA Models"
format: 
  html:
    theme: lux
    code-fold: true
---

```{r, message=FALSE, include=FALSE}
library(tidyverse)
library(tidyquant)
library(ggplot2)
library(forecast)
library(astsa) 
library(xts)
library(tseries)
library(lubridate)
library(plotly)
library(kableExtra)
library(dplyr)

#prescription drug costs
drug = read.csv("datasets/nhe_drug.csv")
drug = head(drug, -10)

drug$Total.Expenditures = as.numeric(gsub(",","",drug$Total.Expenditures))
drug$Out.of.Pocket = as.numeric(gsub(",","",drug$Out.of.Pocket))
drug$Health.Insurance = as.numeric(gsub(",","",drug$Health.Insurance))
drug$Private.Health.Insurance = as.numeric(gsub(",","",drug$Private.Health.Insurance))
drug$Medicare = as.numeric(gsub(",","",drug$Medicare))
drug$Medicaid..Title.XIX. = as.numeric(gsub(",","",drug$Medicaid..Title.XIX.))
drug$Other.Health.Insurance = as.numeric(gsub(",","",drug$Other.Health.Insurance))
drug$Other.Third.Party.Payers.and.Programs = as.numeric(gsub(",","",drug$Other.Third.Party.Payers.and.Programs))
drug$Year = as.Date(paste0(drug$Year, "-12-31"))
drug.ts = subset(drug, select = Out.of.Pocket)
drug.ts = ts(drug.ts, start=1960, frequency = 1)

#us pharma etf
pharma = read.csv("datasets/IHE.csv")
pharma$Date = as.Date(pharma$Date)
pharma.ts = subset(pharma, select = Adj.Close)
pharma.ts = ts(pharma.ts, start=c(2007,1),frequency = 12)

```

### EDA Review: Determining Stationarity of Out-of-Pocket Drug Cost and U.S. Pharmaceutical ETF Datasets

To review, we learned in the EDA tab that the prescription drug cost data is non-stationary based on the results of the ACF plot and the Augmented Dickey-Fuller test, seen below.

```{r, warning=FALSE}
ggAcf(drug.ts, 48, main = "ACF: Prescription Drug Cost TS")

ggPacf(drug.ts, 48, main = "PACF: Prescription Drug Cost TS")

```

```{r, warning=FALSE}
tseries::adf.test(drug.ts)
```

Additionally, we also learned that the U.S. Pharmaceutical ETF closing prices dataset was non-stationary, as seen below.

```{r, warning=FALSE}
ggAcf(pharma.ts, 48, main = "ACF: IHE ETF TS")

ggPacf(pharma.ts, 48, main = "PACF: IHE ETF TS")

```

```{r, warning=FALSE}
tseries::adf.test(pharma.ts)
```

### Detrending and Differencing : Making the Out-of-Pocket Drug Cost Time Series Stationary 

As seen in the last section, we can confirm that both datasets in this study are non-stationary. So, before moving on to ARIMA modeling, it is necessary to transform the dataset so that it is at least weakly stationary. 

```{r}
require(gridExtra)

drug.fit = lm(drug.ts~time(drug.ts), na.action = NULL)

plot1<-autoplot(resid(drug.fit), main="Drug Cost: Detrended") 
plot2<-autoplot(diff(drug.ts), main="Drug Cost: First Difference") 

grid.arrange(plot1, plot2,nrow=2)
```

Next, we can look at the ACF plots to compare the detrended dataset and the differenced dataset. Both detrending and first-order differencing are pretty successful in making the data more stationary. Because the differencing is a bit more successful at making the dataset stationary, I will proceed with that first-order differenced dataset for modeling.

```{r}
require(gridExtra)

# plot1 = ggAcf(drug.ts, 48, main="Original Data: Drug Cost")
plot2 = ggAcf(resid(drug.fit), 48, main="Detrended Data: Drug Cost")
plot3 = ggAcf(diff(drug.ts), 48, main="First Differenced Data: Drug Cost")

grid.arrange(plot2, plot3,nrow=2)
```
```{r}
drug.diff = diff(drug.ts)
```

### ARIMA(p,d,q) Modeling: Out-of-Pocket Prescription Drug Cost

#### Manual Parameter Selection

To determine the p,d, and q parameters for ARIMA, we need to take another look at the ACF and PACF plots.

Because the data was differenced one time, we can say that d will be equal to 1.

There are 3 significant lag terms in the ACF, meaning that the initial q value will be equal to 3. There is 1 significant lag term in the PACF, so the initial p value will be equal to three. 

```{r, warning=FALSE}
ggAcf(drug.diff, 48, main="ACF: Differenced Data")
ggPacf(drug.diff, 48, main="PACF: Differenced Data")
```
We can now proceed with the ARIMA(1,1,3) model.

As seen below, the p-values in the Ljung-Box statistic are very small in most cases, suggesting that the values might be showing some dependence on each other.

The AIC and BIC are 17.6 and 17.8, respectively.

Additionally, we can see that the only the AR(1) and MA(1) coefficients have small enough values to be significant in the model. This means that MA(2) and MA(3) are insignificant, and that removing the second and third MA parameters from the model may improve its performance.

```{r}
set.seed(73)

drug.arima113 = capture.output(sarima(drug.diff, 1,1,3))
```

```{r}
cat(drug.arima113[142:168], drug.arima113[length(drug.arima113)], sep = "\n")
```

Because MA2 and MA3 are insignificant in the model above, I am going to test ARIMA(1,1,1) to see if this improves model performance and reduces error.

Overall, this model seems to perform a bit better than ARIMA(1,1,3). The p-values for Ljung-Box are larger across the board, and the AIC and BIC error have decreased slightly to 17.5 and 17.7, respectively. Additionally, we can see that all coefficients in the model are significant. 

```{r}
set.seed(73)

drug.arima111 = capture.output(sarima(drug.diff, 1,1,1))
```

```{r}
cat(drug.arima111[72:96], drug.arima111[length(drug.arima111)], sep = "\n")
```

As a result, I will be proceeding with ARIMA(1,1,1) as my manually-selected ARIMA model for this dataset.

#### Fitting with auto.arima()

In R, auto.arima() is a function that automatically selects ARIMA parameters when fed a set of time-series data. 

Using the function with the differenced out-of-pocket prescription drug cost dataset, we get:

```{r}
auto.arima(drug.diff)
```
The auto.arima() function suggests that an ARIMA(1,0,0), or AR(1), model is this best for the differenced time series dataset.

Although I was initially suspicious of how this would perform, this model does in fact appear to be a slightly better fit than my previous models. Not only is the coefficient significant, but the Ljung-Box p-values are all significantly different from zero. Additionally, the AIC and BIC have decreased further to 17.4 and 17.5, respectively. 

```{r}
drug.arima100 = capture.output(sarima(drug.diff, 1,0,0))
```
```{r}
cat(drug.arima100[28:50], drug.arima100[length(drug.arima100)], sep = "\n")
```

As seen above, the auto.arima() selection is different than my manually chosen model of ARIMA(1,1,1). I am not exactly sure why this is the case, but it may have something to do with the auto.arima() function prioritizing a lower number of parameters when there is little performance improvement from adding additional parameters. 

#### Forecasting

Next, I want to forecast the next ten years of out-of-pocket drug costs for both my manually-selected ARIMA(1,1,1) model and the auto.arima() selected ARIMA(1,0,0) model.

As can be seen below, there is practically no difference between the two selected models when it comes to forecasting. 


```{r}
drug.diff %>% Arima(order = c(1,1,1), include.drift = TRUE) %>%
  forecast %>%
  autoplot()+
  ylab("Out-of-pocket Drug Cost Predictions")+theme_minimal()
```
```{r}
drug.diff %>% Arima(order = c(1,0,0), include.drift = TRUE) %>%
  forecast %>%
  autoplot()+
  ylab("Out-of-pocket Drug Cost Predictions")+theme_minimal()
```

#### Comparing Benchmark Methods

Finally, I am going to compare my chosen ARIMA model to some simple benchmark models to prove its comparative forecasting power. To do this, I will test the three methods: mean forecasting, naive forecasting, and my ARIMA(1,0,0) and see their ability to predict the ten-year interval from 1995 to 2005. 

As a reminder, here is the time series plot for the first-order differenced data.

```{r}
autoplot(drug.diff)+ggtitle("Out-of-Pocket Drug Costs (1960-2020) (1st-order differenced)")+xlab("Year")+ylab("Out-of-Pocket Cost (Differenced)")
```

Selecting only the the window of interesting, the plot looks like:

```{r}
drug.diff2 = window(drug.diff, start=1960, end=1995)
autoplot(drug.diff2)+ggtitle("Out-of-Pocket Drug Costs (1960-1995) (1st-order differenced)")+xlab("Year")+ylab("Out-of-Pocket Cost (Differenced)")
```


*Mean*

```{r}
drug.mean = meanf(drug.diff2, h=10)
checkresiduals(drug.mean)
```

*Naive Method*

```{r}
drug.naive = naive(drug.diff2, h=10)
checkresiduals(drug.naive)
```

Now, I will plot all forecasts together:

```{r}
autoplot(drug.diff2) +
  autolayer(meanf(drug.diff2, h=10), series = "Mean", PI=FALSE)+
  autolayer(naive(drug.diff2, h=10), series = "Naive", PI=FALSE)+
  
  drug.diff2 %>% Arima(order = c(1,0,0), include.drift = TRUE) %>%
  forecast %>%
  autolayer(series = "ARIMA(1,0,0)", PI=FALSE)+
  
  ggtitle("10-Year Forecast (1995-2005) for Out-of-Pocket Drug Costs")+xlab("Year")+ylab("Out-of-Pocket Cost (Differenced)")+guides(colour=guide_legend(title = "10-Yr Forecast"))
```

When compared to the original data, it is clear that the ARIMA model does a better job of forecasting that the mean and naive methods. That being said, none of the models are able to forecast the incredibly steep spike in out-of-pocket prescription drug costs beginning in 1994.

```{r}
drug.diff3=window(drug.diff, start=1960, end=2005)
autoplot(drug.diff3) +
  autolayer(meanf(drug.diff2, h=10), series = "Mean", PI=FALSE)+
  autolayer(naive(drug.diff2, h=10), series = "Naive", PI=FALSE)+
  
  drug.diff2 %>% Arima(order = c(1,0,0), include.drift = TRUE) %>%
  forecast %>%
  autolayer(series = "ARIMA(1,0,0)", PI=FALSE)+
  
  ggtitle("Forecasting Out-of-Pocket Drug Costs")+xlab("Year")+ylab("Out-of-Pocket Cost (Differenced)")+guides(colour=guide_legend(title = "10-Yr Forecast"))

```















